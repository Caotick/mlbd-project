{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLBD : Project on the music dataset\n",
    "\n",
    "The base subject is : Predicting a playlist that satisfies group members (e.g., to decide the music to play in a party). By playlist we mean a set of artists.\n",
    "\n",
    "Research questions : \n",
    "- Can we generate a playlist of artists for multiple users based on what they listened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "TOP_FOLDER = DATA_FOLDER + 'lastfm-dataset-360k/'\n",
    "GROUP_FOLDER = 'data/groups/'\n",
    "#Using just the artists\n",
    "top_user = pd.read_csv(TOP_FOLDER + 'usersha1-profile.tsv', sep = '\\t', error_bad_lines = False, header = None)\n",
    "top_data = pd.read_csv(TOP_FOLDER + 'usersha1-artmbid-artname-plays.tsv', sep = '\\t', error_bad_lines = False, header = None)\n",
    "\n",
    "# This file was created using the data expansion done in part 3\n",
    "spotify_data = pd.read_csv(DATA_FOLDER + 'full_spotify_info.csv', error_bad_lines = False, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the columns have not proper names, we reformat them in this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to rename the columns\n",
    "top_user.rename(columns = {0 : 'ID', 1 : 'Gender', 2 : 'Age', 3 : 'Country', 4 : 'Registered'}, inplace = True)\n",
    "top_data.rename(columns = {0 : 'ID', 1 : 'Artist_ID', 2 : 'Artist', 3 : 'Plays'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 359'347 users in the users dataset and 17'535'655 entries of type (user, Artist, Plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll check the number of NaNs for each dataset\n",
    "print(top_user.isna().sum(), '\\n')\n",
    "print(top_data.isna().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing entries for the user dataset, however we miss a lot of artist_ID and some artists name. We therefore remove the 204 artists with no name as there we can't recommand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = top_data[top_data['Artist'].isna()].index\n",
    "top_data = top_data.drop(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many artists we have and users that have at least listen to one music:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset has {len(top_data.groupby('Artist').count())} artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users_in_top_data = len(top_data.groupby('ID').count())\n",
    "print(f\"The music dataset has {nb_users_in_top_data} users, meaning that {359347-nb_users_in_top_data} did not listen to anything and have therefore no matching entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spotify API Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to change the Info column from a string to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data = spotify_data.copy()\n",
    "add_data['Info'] = add_data['Info'].map(lambda x: x if isinstance(x, str) else \"{}\").map(lambda x: ast.literal_eval(x))\n",
    "add_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data['Genres'] = add_data['Info'].map(lambda x: x['genres'] if len(x) > 0 else [])\n",
    "add_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = add_data['Genres'].tolist()\n",
    "all_genres = [item for sublist in genres for item in sublist]\n",
    "unique_genres = set(all_genres)\n",
    "len(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(all_genres)\n",
    "c.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_genre(l, c) :\n",
    "    best = \"\"\n",
    "    best_num = 0\n",
    "    for elem in l:\n",
    "        if(c[elem] > best_num) :\n",
    "            best = elem\n",
    "            best_num = c[elem]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data['Most_common_genre'] = add_data['Genres'].map(lambda x: most_common_genre(x, c))\n",
    "add_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_data.groupby('Most_common_genre').size().hist(bins = 25, figsize = (13, 5))\n",
    "plt.yscale('log')\n",
    "plt.title('Number of artists which have the same best genre')\n",
    "plt.xlabel('Number of artists')\n",
    "_ = plt.ylabel('Number of genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data.groupby('Most_common_genre').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that there are 11522 artists which do not have any genres attached to them, this probably comes from a lack of information about these artists in general from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data = add_data[add_data['Genres'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data.groupby('Most_common_genre').size().hist(bins = 25, figsize = (13, 5))\n",
    "plt.yscale('log')\n",
    "plt.title('Number of artists which have the same best genre (without no genre)')\n",
    "plt.xlabel('Number of artists')\n",
    "_ = plt.ylabel('Number of genres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some issues with the Spotify API part where Artist such as She will be take as Ed Sheeran. This will be fixed by setting a bigger threshold on the number of users which are listening to the same artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data_percent = top_data.copy()\n",
    "top_data_percent['Percent'] = top_data['Plays'] / top_data[['ID', 'Plays']].groupby('ID').Plays.transform('sum')\n",
    "top_data_percent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = top_data_percent.merge(add_data, on = 'Artist')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['Most_common_genre', 'Percent']].groupby('Most_common_genre').sum().hist(bins = 100, figsize = (13, 5))\n",
    "plt.yscale('log')\n",
    "plt.title('Sum of percent of listening time per genre')\n",
    "plt.xlabel('Sum of percent')\n",
    "_ = plt.ylabel('Number of genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['Most_common_genre', 'Percent']].groupby('Most_common_genre').sum().sort_values(by = 'Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the 17'535'655 entries, we now have 15'553'756 that have possess a lot more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the number of users that have listened to one artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_nb_users_listen= all_data.groupby(['Artist']).size().sort_values(ascending = True).reset_index(name = 'nb_users')\n",
    "# we check how many times an artist occurs in dataset\n",
    "artists_nb_users_listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_nb_users_listen.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the distribution is exponential. More than 25% of the artists that have a matching entry in the spotify API have been listened only by 37 users, 50% by 80, 75% by 242.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(artists_nb_users_listen['nb_users'], log_scale = True)\n",
    "plt.title(\"Nb users listening to one artist\")\n",
    "plt.ylabel(\"Nb of artists\")\n",
    "plt.xlabel(\"Nb of users\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now look at the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_nb_artists_listen = top_data.groupby('ID').size().sort_values().reset_index(name = 'nb_artists_listen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_nb_artists_listen.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we see that, although we have a lot of artists, users tend to listen to only a few of them. In average, a users has listened to 49 different artists with the quantiles being near from each other which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see from where our users come from. It's possible that the origin of the user has an impact on what he listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users_per_country = top_user.groupby('Country').size().reset_index(name = 'nb_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users_per_country = nb_users_per_country.sort_values('nb_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only plotting the countries with more than 2000 users in the database\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.barplot(ax= ax, data = nb_users_per_country[nb_users_per_country['nb_users']>2000], x = 'nb_users', y = 'Country', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that most of our users come from the United States, Germany and the United Kingdom. More generally, we have a lot of european music culture with the exception of Brazil, Japan, Turkey, Mexico, Chile and Argentinia. We will therefore have that the most listened artists come from this culture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to merge the two dataset together to continue the exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_merged = all_data.merge(top_user, left_on='ID', right_on='ID')\n",
    "top_merged = top_merged.drop(columns=['Artist_ID']) ##Drop when the users was registered and the artist_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! it seems that we lose approximetely 100k users by merging two datasets above. \n",
    "# But I guess we can't do anything with that, but probably it's good to mention it in eda ~rap\n",
    "\n",
    "# We decide to eliminate users, which have listened to less than 10 favourite artists (We'll use trivial recommendation for them)\n",
    "top_merged_IDs = top_merged.groupby(['ID']).size().reset_index()\n",
    "users_id = top_merged_IDs[top_merged_IDs[0] > 10]['ID']\n",
    "top_merged = top_merged[top_merged['ID'].isin(users_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if artists are more listened to one country or another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_per_country = top_merged[['Artist', 'Country', 'ID', 'Plays']].groupby(['Artist','Country']).agg({'ID': len,\n",
    "                             'Plays': 'sum'}).rename(columns = {'ID':'nb_users'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_per_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can also look at the most listened artist in one country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_artist_per_country = artists_per_country.unstack(1, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_artist_per_country = top1_artist_per_country.reset_index()\n",
    "top1_artist_per_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_artist_per_country = top1_artist_per_country.set_index(top1_artist_per_country['Artist']).drop(columns = 'Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in top1_artist_per_country['nb_users']:\n",
    "    print(f\"Most listened artist in {country}: {top1_artist_per_country['nb_users'][country].idxmax()}, with {top1_artist_per_country['nb_users'][country].max()} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at it in terms of plays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in top1_artist_per_country['Plays']:\n",
    "    print(f\"Most listened artist in {country}: {top1_artist_per_country['Plays'][country].idxmax()}, with {top1_artist_per_country['Plays'][country].max()} plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number of plays and users that listen to an artist doesn't always lead to the same top result. However we can argue that there seem to be cultural differences between the countries leading to different top groups/genres. For example, most nordic countries, have a rock/metal group as top position, while more West-European tend to listen to pop.\n",
    "\n",
    "\n",
    "We therefore decide to inspect for each users, the max number of plays they have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_top = top_data.groupby(['ID'])['Plays'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_top.reset_index().hist(bins = 100, figsize = (13, 5))\n",
    "plt.yscale('log')\n",
    "plt.title('Number of plays for most listened artist per user')\n",
    "plt.xlabel('Number of plays')\n",
    "plt.ylabel('Number of users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_data[top_data['Plays'] == top_data['Plays'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most user can be found at the start of scale (notice the logY scale), but some users are truly amazing, with the max plays sitting at 419157. After some research, nofx, the artist this user has been listening to, mainly makes music of about 2 minutes, still this user has more or less listened to 1.6 years of nofx in about 4 years. We really suspect that this is due to a bot. To not have this kind of biases, we argue that taking the number of users listening to an artist is more representative of its fame in the corresponding country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user[top_user['ID'] == '8d0384537845e7f2b1b8b3e8a9f67eb8d9439794']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Measurement of the quality of the individual recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the dataframe into a train and a test set randomly\n",
    "def split_train_test(df, train_size = 0.9 ,seed = 42, apply_seed = False):\n",
    "    uniques_ids = df.ID.unique()\n",
    "    if apply_seed:\n",
    "        np.random.seed(seed)\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    for user_id in uniques_ids:\n",
    "        user_sub = df[df['ID'] == user_id]\n",
    "        randomization = np.random.permutation(user_sub.index)\n",
    "        user_sub_train = user_sub.loc[randomization[0:int(len(randomization)*train_size)]]\n",
    "        user_sub_test = user_sub.loc[randomization[int(len(user_sub)*train_size):len(user_sub)]]\n",
    "        \n",
    "        train = train.append(user_sub_train)\n",
    "        test = test.append(user_sub_test)\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes just mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(pred_method, helper_df):\n",
    "    mae = 0\n",
    "    for i, row in test.iterrows():\n",
    "        user = row.ID\n",
    "        artist = row.Artist\n",
    "        prediction = pred_method(user, artist, helper_df)\n",
    "        mae += abs(row.Plays - prediction)\n",
    "    return mae/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_appreciation(pred_method, helper_df, user_specific_threshold = None, threshold = 100):\n",
    "    predictions = np.zeros(len(test))\n",
    "    reals = np.zeros(len(test))\n",
    "    indice = 0\n",
    "    for i, row in test.iterrows():\n",
    "        user = row.ID\n",
    "        artist = row.Artist\n",
    "        prediction = pred_method(user, artist, helper_df)\n",
    "        predictions[indice] = prediction > threshold\n",
    "        reals[indice] = row.Plays > threshold\n",
    "        indice += 1\n",
    "    \n",
    "    tp = np.sum(np.bitwise_and(predictions==1, reals == 1))\n",
    "    fp = np.sum(np.bitwise_and(predictions==1, reals == 0))\n",
    "    \n",
    "    fn = np.sum(np.bitwise_and(predictions== 0, reals == 1))\n",
    "    \n",
    "    acc = np.sum(predictions == reals)\n",
    "    \n",
    "    return mae/len(test_df), acc/len(test_df), tp/(tp+fp), tp/(tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes mae, accuracy, precision and recall in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae_and_app(test_df, pred_method, helper_df, threshold = 250):\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    reals = np.zeros(len(test_df))\n",
    "    indice = 0\n",
    "    mae = 0\n",
    "    for i, row in test_df.iterrows():\n",
    "        user = row.ID\n",
    "        artist = row.Artist\n",
    "        prediction = pred_method(user, artist, helper_df)\n",
    "        mae += abs(row.Plays - prediction)\n",
    "        predictions[indice] = prediction > threshold\n",
    "        reals[indice] = row.Plays > threshold\n",
    "        indice += 1\n",
    "    \n",
    "    tp = np.sum(np.bitwise_and(predictions==1, reals == 1))\n",
    "    fp = np.sum(np.bitwise_and(predictions==1, reals == 0))\n",
    "    \n",
    "    fn = np.sum(np.bitwise_and(predictions== 0, reals == 1))\n",
    "    \n",
    "    acc = np.sum(predictions == reals)\n",
    "    \n",
    "    return mae/len(test_df), acc/len(test_df), tp/(tp+fp), tp/(tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae_and_app_knn(test_df, pred_method, threshold = 100):\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    reals = np.zeros(len(test_df))\n",
    "    indice = 0\n",
    "    mae = 0\n",
    "    for i, row in test_df.iterrows():\n",
    "        user = row.ID\n",
    "        artist = row.Artist\n",
    "        prediction = pred_method(user, artist, test_df)\n",
    "        if type(prediction) == np.float64:\n",
    "            mae += abs(row.Plays - prediction)\n",
    "            predictions[indice] = prediction \n",
    "            prediction > threshold\n",
    "            reals[indice] = row.Plays > threshold\n",
    "            indice += 1\n",
    "    \n",
    "    tp = np.sum(np.bitwise_and(predictions==1, reals == 1))\n",
    "    fp = np.sum(np.bitwise_and(predictions==1, reals == 0))\n",
    "\n",
    "    fn = np.sum(np.bitwise_and(predictions== 0, reals == 1))\n",
    "\n",
    "    acc = np.sum(predictions == reals)\n",
    "    \n",
    "    return mae/len(test_df), acc/len(test_df), tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_rounds(pred_method, nb_users_selected = 500, n = 10, seed = 42):\n",
    "    \"\"\"\n",
    "    Computes the mae, accuracy, precision and recall on n round of the pred_method\n",
    "    \n",
    "    pred_method = method that allows to compute the prediction\n",
    "    nb_users_selected = number of users in the sub-sample\n",
    "    n = number of rounds\n",
    "    seed = seed for random generation of sub-samples\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    maes, accs, precs, recs = [],[],[],[]\n",
    "    nb_users = len(top_merged[['ID']].groupby('ID'))\n",
    "    df = top_merged.groupby('ID').size()\n",
    "    rng = np.random.default_rng(seed = seed)\n",
    "    \n",
    "    for i in range(n):\n",
    "        print(f\"===== Epoch {i} =====\")\n",
    "        selected_users = rng.choice(nb_users, nb_users_selected, replace = False) #Generate a random list of nb_users_select users\n",
    "        subset_500_users = df[selected_users]\n",
    "        subset = top_merged[top_merged.ID.isin(subset_500_users.index)]\n",
    "        train, test = split_train_test(subset, train_size=0.95)\n",
    "\n",
    "        if pred_method == compute_pred_avg_user:\n",
    "            avg_user_listens = train[['ID', 'Plays']].groupby(\"ID\").mean('Plays').reset_index()\n",
    "            mae, acc, prec, rec = compute_mae_and_app(test, pred_method, avg_user_listens)\n",
    "\n",
    "        elif pred_method == compute_pred_avg_artist:\n",
    "            avg_artist_listens = train[['Artist', 'Plays']].groupby(\"Artist\").mean('Plays').reset_index()\n",
    "            mae, acc, prec, rec = compute_mae_and_app(test, pred_method, avg_artist_listens)\n",
    "        elif pred_method == compute_pred_knn:\n",
    "            mae, acc, prec, rec = compute_mae_and_app_knn(subset, pred_method)\n",
    "        else:\n",
    "            mae, acc, prec, rec = compute_mae_and_app(test, pred_method, train) #sim measures doesn't a helper set\n",
    "        \n",
    "        maes.append(mae)\n",
    "        accs.append(acc)\n",
    "        precs.append(prec)\n",
    "        recs.append(rec)\n",
    "        \n",
    "    return maes, accs, precs, recs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Measurment of the quality of the group recommender systems:\n",
    "\n",
    "For the group recommendation system. We use a least measury principle, meaning we want to satisfy the most users. So for each user we need to get the number of plays, if it is over a certain threshold, we consider he likes it, otherwise not. We then aggregate all the individual predictions and try to select the artist with the most likes.\n",
    "\n",
    "To measure the performance of this we use the Discounted Cumulative Gain (DCG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_recommendation_according_to_our_algorithm(users, same_artists, df, threshold = 250):\n",
    "    recommendations = pd.DataFrame(columns = [\"Artist\", \"nb_likes\"])\n",
    "    for artist in same_artists:\n",
    "        nb_likes = 0\n",
    "        for user in users:\n",
    "            if df[(df['ID'] == user) & (df['Artist'] == artist)].iloc[0]['Plays'] > threshold:\n",
    "                nb_likes += 1\n",
    "        recommendations = recommendations.append({\"Artist\": artist, \"nb_likes\" : nb_likes}, ignore_index = True)\n",
    "    return recommendations.sort_values(\"nb_likes\", ascending=False).reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_plays(user, artist, df):\n",
    "    res = df[(df['ID'] == user) & (df['Artist'] == artist)]\n",
    "    if len(res) == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return res.iloc[0]['Plays']\n",
    "\n",
    "def test_recommender(pred_method, df, helper_df, group_of_users, same_artists, threshold = 250):\n",
    "    list_of_artists = dict()\n",
    "    \n",
    "    for user in group_of_users:\n",
    "        nb_likes = 0\n",
    "        for artist in df[(df['ID'] == user) & (df['Artist'].isin(same_artists))]['Artist']:\n",
    "            list_of_artists[artist] = 0\n",
    "    \n",
    "    for artist in list_of_artists.keys():\n",
    "        for user in group_of_users:\n",
    "            if(user == group_of_users[0]): #Always takes first user because selection is randomized\n",
    "                nb_plays = get_nb_plays(user, artist, df)\n",
    "            \n",
    "            else: nb_plays = -1\n",
    "                \n",
    "            if nb_plays != -1:\n",
    "                if nb_plays > threshold:\n",
    "                    list_of_artists[artist] += 1\n",
    "            \n",
    "            else:\n",
    "                prediction = pred_method(user, artist, helper_df)\n",
    "                if prediction > threshold:\n",
    "                    list_of_artists[artist] += 1\n",
    "    \n",
    "    recommendation = pd.DataFrame(columns = [\"Artist\", \"nb_likes\"])\n",
    "    \n",
    "    for entry in list_of_artists:\n",
    "        recommendation = recommendation.append({\"Artist\":entry, \"nb_likes\":list_of_artists[entry]}, ignore_index = True)\n",
    "    \n",
    "    return recommendation.sort_values(\"nb_likes\", ascending = False).reset_index().drop(columns = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_idcg(reals, preds):\n",
    "    reals['Rank'] = [i for i in range(1, len(reals)+ 1)]\n",
    "    preds['Rank'] = [i for i in range(1, len(reals)+ 1)] #Not same rank for items rated equally\n",
    "    final = reals.merge(preds, on = 'Artist')\n",
    "    log_ranks_pred = np.log2(final['Rank_y'])\n",
    "    log_ranks_pred = log_ranks_pred.where(log_ranks_pred > 0, 1)\n",
    "    log_ranks_real = np.log2(final['Rank_x'])\n",
    "    log_ranks_real = log_ranks_real.where(log_ranks_real > 0, 1)\n",
    "    DCG = np.sum(final['nb_likes_x']/log_ranks_pred)\n",
    "    IDCG = np.sum(final['nb_likes_x']/log_ranks_real)\n",
    "    if IDCG == 0: #Case nobody has liked anything\n",
    "        return 1.0\n",
    "    return DCG/IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_group_recommendation(pred_method, group_df, helper_df, rng):\n",
    "    users = group_df['ID'].unique()\n",
    "    measures = []\n",
    "    rng = rng\n",
    "    for nb_pred in range(10):\n",
    "        random_6_users = rng.choice(len(users), 6, replace = False)\n",
    "        my_6_users_group = users[random_6_users]\n",
    "        \n",
    "        aggregated_set = group_df[group_df['ID'].isin(users)][['ID','Artist']].groupby('ID').agg(set)\n",
    "        same_artists = aggregated_set.iloc[0]['Artist']\n",
    "        for i,row in aggregated_set.iterrows():\n",
    "            same_artists = same_artists.intersection(row['Artist'])\n",
    "        \n",
    "        random_5_artists = np.array(list(same_artists))\n",
    "        random_5_artists = random_5_artists[rng.choice(len(same_artists), 5, replace = False)]\n",
    "        \n",
    "        reals = get_group_recommendation_according_to_our_algorithm(my_6_users_group, random_5_artists, group)\n",
    "        preds = test_recommender(pred_method, group, helper_df, users, random_5_artists)\n",
    "        measures.append(dcg_idcg(reals, preds))\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing different prediction method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting only based on the user average listens\n",
    "\n",
    "Trivially predict the mean of the user: $\\large pred(u,i) = \\mu_{u} = \\sum_{k \\in I(u)} \\frac{Plays(u, k)}{|I(u)|}$\n",
    "\n",
    "where, $u$ is the usere we're making the prediction for, $i$ is the artist we want to predict the number of plays, $I(u)$ is the set of Artist the user has listened to.\n",
    "\n",
    "Have still to measure the performance ? How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_avg_user(user, artist_i, avg_listens):\n",
    "    return int(avg_listens[avg_listens['ID'] == user]['Plays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "maes_users, accs_users, precs_users, recs_users = compute_n_rounds(compute_pred_avg_user)\n",
    "end = time.time()\n",
    "print(f\"Time required to do the prediction on 10 rounds {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(maes_users, columns = [\"Mae_User_avg\"]))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Mean absolute error on 10 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame({\"Accuracy_User_avg\":accs_users, \"Precision_User_avg\":precs_users, \"Recall_User_avg\":recs_users}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on group prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "group_pred_measures = []\n",
    "rng = np.random.default_rng(seed = 42)\n",
    "for i in range(10):\n",
    "    measures = []\n",
    "    for file in os.listdir(GROUP_FOLDER):\n",
    "        group = pd.read_csv(f'{GROUP_FOLDER}{file}').drop(columns = ['Unnamed: 0'])\n",
    "        measures.append(measure_group_recommendation(compute_pred_avg_user, group, group.groupby('ID').mean('Plays').reset_index(), rng))\n",
    "    group_pred_measures.append(np.hstack(np.array(measures)).mean())\n",
    "    print(f\"Finished round {i}\")\n",
    "groups_user_avg = group_pred_measures\n",
    "end = time.time()\n",
    "print(f\"Time required to do the predictions on 10 rounds {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(groups_user_avg, columns = [\"DCG\"]))\n",
    "plt.title(\"DCG on 120 groups for 10 epochs (User Avg)\")\n",
    "plt.ylim(0.8, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting only based on the artist average listens\n",
    "\n",
    "\n",
    "Trivially predict the mean of the artist for each user: $\\large pred(u,i) = \\mu_{i} =\\sum_{v \\in U(i)} \\frac{Plays(v,i)}{|U(i)|}$\n",
    "\n",
    "where $U(i)$ is the set of users that has listened artist i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_avg_artist(user, artist_i, avg_listens):\n",
    "    prediction = avg_listens[avg_listens['Artist'] == artist_i]\n",
    "    if len(prediction) == 0: \n",
    "        return int(avg_listens['Plays'].mean()) # What to return when we haven't seen the artist?\n",
    "    else:\n",
    "        return int(prediction['Plays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_artist = time.time()\n",
    "maes_artists, accs_artists, precs_artists, recs_artists = compute_n_rounds(compute_pred_avg_artist)\n",
    "end_artist = time.time()\n",
    "print(f\"Time required to do the prediction on 10 rounds {end_artist - start_artist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(maes_artists, columns = [\"Mae_Artist_avg\"]))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Mean absolute error on 10 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame({\"Accuracy_Artist_avg\":accs_artists, \"Precision_Artist_avg\":precs_artists, \"Recall_Artist_avg\":recs_artists}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on Group prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "group_pred_measures = []\n",
    "rng = np.random.default_rng(seed = 42)\n",
    "avg_artist_plays = top_merged.groupby('Artist').mean('Plays').reset_index()\n",
    "for i in range(10):\n",
    "    measures = []\n",
    "    for file in os.listdir(GROUP_FOLDER):\n",
    "        group = pd.read_csv(f'{GROUP_FOLDER}{file}').drop(columns = ['Unnamed: 0'])\n",
    "        measures.append(measure_group_recommendation(compute_pred_avg_artist, group,\n",
    "                                                     avg_artist_plays[avg_artist_plays['Artist'].isin(group['Artist'])] , rng))\n",
    "    group_pred_measures.append(np.hstack(np.array(measures)).mean())\n",
    "    print(f\"Finished round {i}\")\n",
    "groups_artist_avg = group_pred_measures\n",
    "end = time.time()\n",
    "print(f\"Time required to do the predictions on 10 rounds {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(groups_artist_avg, columns = [\"DCG\"]))\n",
    "plt.title(\"DCG on 120 groups for 10 epochs\")\n",
    "plt.ylim(0.8, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using User similarity\n",
    "\n",
    "**User specific prediction**: Compute similarity based on Jaccard distance: Each user has a set of artist he has listened to.\n",
    "\n",
    "$\\large sim(u,v)$ = Jacc$(I(u), I(v))$ = $\\Large \\frac{|I(u) \\cap I(v)|}{|I(u) \\cup I(v)|}$\n",
    "\n",
    "Once we have this similarity, check if a new artist will be listened a lot by the user by comparing it to all the other users that have listened to him, this is the user-specific sum : \n",
    "\n",
    "$\\large \\tilde{u} =  \\frac{\\sum_{v \\in U(i)} sim(u,v) \\cdot (Plays(v,i) - \\mu_{v})}{ \\sum_{v \\in U(i)} sim(u,v)} $\n",
    "\n",
    "where $U(i)$ is the set of users that have listened to the group $i$\n",
    "\n",
    "and add the mean of the user to it so we have:\n",
    "\n",
    "$\\large pred(u, i) = \\mu_{u} + \\tilde{u} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_user_item(user, artist, df):\n",
    "    user_artists = set(df[df['ID'] == user]['Artist']) #Get the set of the current user we want to get the prediction from\n",
    "    artist_has_user = set(df[(df['Artist'] == artist) & (df['ID'] != user)]['ID']) #Set of artist that have rated the user\n",
    "    \n",
    "    num = 0\n",
    "    denom = 0\n",
    "    \n",
    "    for i, x in enumerate(artist_has_user):\n",
    "        user_i_artists = set(df[df['ID'] == x]['Artist'])\n",
    "        sim_with_i = len(user_artists.intersection(user_i_artists))/len(user_artists.union(user_i_artists))\n",
    "        \n",
    "        num += sim_with_i * (int(df[(df['ID'] == x) & (df['Artist'] == artist)]['Plays']) - int(df[df['ID'] == x]['Plays'].mean()))\n",
    "        denom += sim_with_i\n",
    "    \n",
    "    if denom == 0:\n",
    "        return df[df['ID'] == user]['Plays'].mean()\n",
    "    else:\n",
    "        return df[df['ID'] == user]['Plays'].mean() + num/denom\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_artist = time.time()\n",
    "maes_sim, accs_sim, precs_sim, recs_sim = compute_n_rounds(compute_pred_user_item)\n",
    "end_artist = time.time()\n",
    "print(f\"Time required to do the prediction on 10 rounds {end_artist - start_artist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(maes_sim, columns = [\"Mae_User_sim\"]))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Mean absolute error on 10 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame({\"Accuracy_User_sim\":accs_sim, \"Precision_User_sim\":precs_sim, \"Recall_User_sim\":recs_sim}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results on group prediction\n",
    "\n",
    "**This takes too much time**\n",
    "\n",
    "Furthermore we observed that it was less good for individual predictions, so this measure is a bit useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "start = time.time()\n",
    "group_pred_measures = []\n",
    "df = top_merged.groupby('ID').size()\n",
    "nb_users = len(df)\n",
    "rng = np.random.default_rng(seed = 42)\n",
    "for i in range(10):\n",
    "    measures = []\n",
    "    \n",
    "    selected_users = rng.choice(nb_users, 500, replace = False) #Generate a random list of nb_users_select users\n",
    "    subset_500_users = df[selected_users]\n",
    "    subset = top_merged[top_merged.ID.isin(subset_500_users.index)] #Subset to compare our group members too\n",
    "    \n",
    "    for file in os.listdir(GROUP_FOLDER):\n",
    "        group = pd.read_csv(f'{GROUP_FOLDER}{file}').drop(columns = ['Unnamed: 0'])\n",
    "        measures.append(measure_group_recommendation(compute_pred_user_item, group,\n",
    "                                                      subset, rng))\n",
    "    group_pred_measures.append(np.array(measures).flatten().mean())\n",
    "    print(f\"Finished round {i}\")\n",
    "group_user_avg = group_pred_measures\n",
    "end = time.time()\n",
    "print(f\"Time required to do the predictions on 10 rounds {end - start}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using KNN\n",
    "\n",
    "**User specific prediction**: Still computes similarity between the users but uses the only the k neirest neighbors to make the predictions.\n",
    "\n",
    "$\\large \\tilde{u} =  \\frac{\\sum_{v \\in KNN(i)} sim(u,v) \\cdot (Plays(v,i) - \\mu_{v})}{ \\sum_{v \\in KNN(i)} sim(u,v)} $\n",
    "\n",
    "where $KNN(i)$ is the set of neighbors of $u$ that have listened to the group $i$.\n",
    "\n",
    "and then do as before:\n",
    "\n",
    "$\\large p(u, i) = \\mu_{u} + \\tilde{u} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "def compute_pred_knn(user_knn, artist, df, neighbors = 20):\n",
    "    artist_has_user = np.unique(df[(df['Artist'] == artist)]['ID']) #Set of users who have listened to the chosen artist\n",
    "    df = df[df['ID'].isin(artist_has_user)] \n",
    "    users = np.unique(df['ID'])\n",
    "    \n",
    "    if len(users) >= neighbors:\n",
    "\n",
    "        knn_pivot = df.pivot(index = 'ID', columns = 'Artist', values = 'Plays').fillna(0)\n",
    "        model_knn = NearestNeighbors(metric='jaccard', algorithm='brute', n_neighbors=neighbors, n_jobs=-1)\n",
    "        model_knn.fit(knn_pivot)\n",
    "\n",
    "        distances, indices =model_knn.kneighbors(knn_pivot, n_neighbors= neighbors)\n",
    "        distances = distances[:,1:] #eliminate comparing user_i with himself\n",
    "        indices = indices[:,1:] #eliminate comparing user_i with himself\n",
    "\n",
    "        indices_lists = zip(users, indices)\n",
    "        distances_lists = zip(users, distances)\n",
    "        indices_dict = dict(indices_lists)\n",
    "        distances_dict = dict(distances_lists)\n",
    "\n",
    "        if artist in list(df[df['ID'] == user_knn]['Artist']):\n",
    "            closest_users = users[indices_dict[user_knn]]\n",
    "            sum_of_similarities = distances_dict[user_knn].sum()\n",
    "            prediction = []\n",
    "\n",
    "            for index, user_knn in enumerate(closest_users):\n",
    "                similarity = distances_dict[user_knn][index]\n",
    "                user_mean = df[df['ID'] == user_knn]['Plays'].mean()\n",
    "                user_artists = df[df['ID'] == user_knn]\n",
    "                user_plays = int(user_artists[user_artists['Artist'] == artist]['Plays'])\n",
    "                pre_similarity = similarity*(user_plays - user_mean)\n",
    "                prediction.append(pre_similarity)\n",
    "\n",
    "            if sum_of_similarities == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return (np.sum(prediction))/sum_of_similarities  \n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 15 mins to compute\n",
    "start = time.time()\n",
    "maes_knn, accs_knn, precs_knn, recs_knn = compute_n_rounds(compute_pred_knn)\n",
    "end = time.time()\n",
    "print(f\"Time required to do the prediction on 1 round {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(maes_knn, columns = [\"KNN_sim\"]))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Mean absolute error on for knn approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(accs_knn, columns = [\"KNN_sim\"]))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for knn approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting based on the average number of plays per genre and user\n",
    "\n",
    "The mean number of plays per genre and user is computed as : $\\large pred(u,i) = \\mu_{u,g} = \\sum_{k \\in I(u, g)} \\frac{Plays(u, k)}{|I(u, g)|}$\n",
    "\n",
    "where $u$ the user, $i$ the artist, $g$ the most common genre associated with the artist, and $I(u, g)$ the set of artists listened to by the user which have the same most common genre as the artist for which we are computing the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_genres_users = top_merged.groupby(['ID', 'Most_common_genre'])['Plays'].mean()\n",
    "mean_genres_users = mean_genres_users.reset_index()\n",
    "mean_genres_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_genre_avg_user(user, artist, mean_genres_users, artist_most_common) :\n",
    "    most_common = artist_most_common[artist_most_common['Artist'] == artist].Most_common_genre.iloc[0]\n",
    "    return mean_genres_users[(mean_genres_users['ID'] == user) & (mean_genres_users['Most_common_genre'] == most_common)].Plays.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing individual predictions**\n",
    "\n",
    "**Previous function doesn't match the need of this method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae_and_app_genre(test_df, mean_genres_users, artist_most_common, threshold = 100):\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    reals = np.zeros(len(test_df))\n",
    "    indice = 0\n",
    "    mae = 0\n",
    "    for i, row in test_df.iterrows():\n",
    "        user = row.ID\n",
    "        artist = row.Artist\n",
    "        prediction = compute_pred_genre_avg_user(user, artist, mean_genres_users, artist_most_common)\n",
    "        mae += abs(row.Plays - prediction)\n",
    "        predictions[indice] = prediction > threshold\n",
    "        reals[indice] = row.Plays > threshold\n",
    "        indice += 1\n",
    "    \n",
    "    tp = np.sum(np.bitwise_and(predictions==1, reals == 1))\n",
    "    fp = np.sum(np.bitwise_and(predictions==1, reals == 0))\n",
    "    \n",
    "    fn = np.sum(np.bitwise_and(predictions== 0, reals == 1))\n",
    "    \n",
    "    acc = np.sum(predictions == reals)\n",
    "    \n",
    "    return mae/len(test_df), acc/len(test_df), tp/(tp+fp), tp/(tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_rounds_genre(nb_users_selected = 500, n = 10, seed = 42):\n",
    "    \"\"\"\n",
    "    Computes the mae, accuracy, precision and recall on n round of the pred_method\n",
    "    \n",
    "    pred_method = method that allows to compute the prediction\n",
    "    nb_users_selected = number of users in the sub-sample\n",
    "    n = number of rounds\n",
    "    seed = seed for random generation of sub-samples\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    maes, accs, precs, recs = [],[],[],[]\n",
    "    df = top_merged[['ID', 'Artist', 'Plays']]\n",
    "    df2 = df.groupby('ID').size()\n",
    "    nb_users = len(top_merged.ID.unique())\n",
    "    \n",
    "    for i in range(n):\n",
    "        print(f\"===== Epoch {i} =====\")\n",
    "        selected_users = np.random.randint(0, nb_users, nb_users_selected) #Generate a random list of nb_users_select users\n",
    "        subset_500_users = df2[selected_users]\n",
    "        subset = df[df.ID.isin(subset_500_users.index)]\n",
    "        train, test = split_train_test(subset, train_size=0.95)\n",
    "        test_genre_users = mean_genres_users[mean_genres_users.ID.isin(test.ID)]\n",
    "        \n",
    "        mae, acc, prec, rec = compute_mae_and_app_genre(test, test_genre_users, add_data[['Artist', 'Most_common_genre']])\n",
    "        \n",
    "        maes.append(mae)\n",
    "        accs.append(acc)\n",
    "        precs.append(prec)\n",
    "        recs.append(rec)\n",
    "        \n",
    "    return maes, accs, precs, recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recommender_genre(df, mean_genres_users, artist_most_common, group_of_users, same_artists, threshold = 250):\n",
    "    list_of_artists = dict()\n",
    "    \n",
    "    for user in group_of_users:\n",
    "        nb_likes = 0\n",
    "        for artist in df[(df['ID'] == user) & (df['Artist'].isin(same_artists))]['Artist']:\n",
    "            list_of_artists[artist] = 0\n",
    "    \n",
    "    for artist in list_of_artists.keys():\n",
    "        for user in group_of_users:\n",
    "            if(user == group_of_users[0]): #Always takes first user because selection is randomized\n",
    "                nb_plays = get_nb_plays(user, artist, df)\n",
    "            \n",
    "            else: nb_plays = -1\n",
    "                \n",
    "            if nb_plays != -1:\n",
    "                if nb_plays > threshold:\n",
    "                    list_of_artists[artist] += 1\n",
    "            \n",
    "            else:\n",
    "                prediction = compute_pred_genre_avg_user(user, artist, mean_genre_users)\n",
    "                if prediction > threshold:\n",
    "                    list_of_artists[artist] += 1\n",
    "    \n",
    "    recommendation = pd.DataFrame(columns = [\"Artist\", \"nb_likes\"])\n",
    "    \n",
    "    for entry in list_of_artists:\n",
    "        recommendation = recommendation.append({\"Artist\":entry, \"nb_likes\":list_of_artists[entry]}, ignore_index = True)\n",
    "    \n",
    "    return recommendation.sort_values(\"nb_likes\", ascending = False).reset_index().drop(columns = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_group_recommendation_genre(mean_genres_users, artist_most_common, group_df, rng):\n",
    "    users = group_df['ID'].unique()\n",
    "    measures = []\n",
    "    rng = rng\n",
    "    for nb_pred in range(10):\n",
    "        random_6_users = rng.choice(len(users), 6, replace = False)\n",
    "        my_6_users_group = users[random_6_users]\n",
    "        \n",
    "        aggregated_set = group_df[group_df['ID'].isin(users)][['ID','Artist']].groupby('ID').agg(set)\n",
    "        same_artists = aggregated_set.iloc[0]['Artist']\n",
    "        for i,row in aggregated_set.iterrows():\n",
    "            same_artists = same_artists.intersection(row['Artist'])\n",
    "        \n",
    "        random_5_artists = np.array(list(same_artists))\n",
    "        random_5_artists = random_5_artists[rng.choice(len(same_artists), 5, replace = False)]\n",
    "        \n",
    "        reals = get_group_recommendation_according_to_our_algorithm(my_6_users_group, random_5_artists, group)\n",
    "        preds = test_recommender_genre(group_df, mean_genres_users, artist_most_common, group, random_5_artists)\n",
    "        measures.append(dcg_idcg(reals, preds))\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "maes_genres, accs_genres, precs_genres, recs_genres = compute_n_rounds_genre()\n",
    "end = time.time()\n",
    "print(f\"Time required to do the prediction on 10 rounds {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(maes_genres, columns = [\"Mae_Artist_avg\"]))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Mean absolute error on 10 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame({\"Accuracy_Artist_avg\":accs_genres, \"Precision_Artist_avg\":precs_genres, \"Recall_Artist_avg\":recs_genres}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "group_pred_measures = []\n",
    "rng = np.random.default_rng(seed = 42)\n",
    "\n",
    "for i in range(10):\n",
    "    measures = []\n",
    "    for file in os.listdir(GROUP_FOLDER):\n",
    "        group = pd.read_csv(f'{GROUP_FOLDER}{file}').drop(columns = ['Unnamed: 0'])\n",
    "        measures.append(measure_group_recommendation_genre(maes_genres, add_data[['Artist', 'Most_common_genre']], group, rng))\n",
    "    group_pred_measures.append(np.hstack(np.array(measures)).mean())\n",
    "    print(f\"Finished round {i}\")\n",
    "groups_genres = group_pred_measures\n",
    "end = time.time()\n",
    "print(f\"Time required to do the predictions on 10 rounds {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = pd.DataFrame(groups_artist_avg, columns = [\"DCG\"]))\n",
    "plt.title(\"DCG on 120 groups for 10 epochs\")\n",
    "plt.ylim(0.8, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison between techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (15,6))\n",
    "measurments_df = pd.DataFrame(columns = ['method', 'mae_acc_prec_rec', 'measurement_method']) \n",
    "\n",
    "\n",
    "for i in range(len(maes_genres)):\n",
    "    measurments_df= measurments_df.append({'method':'Genre Similarity', 'mae_acc_prec_rec':maes_genres[i], 'measurement_method':'MAE'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Genre Similarity', 'mae_acc_prec_rec':accs_genres[i], 'measurement_method':'Accuracy'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Genre Similarity', 'mae_acc_prec_rec':precs_genres[i], 'measurement_method':'Precision'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Genre Similarity', 'mae_acc_prec_rec':recs_genres[i], 'measurement_method':'Recall'}, ignore_index = True)\n",
    "\n",
    "for i in range(len(maes_users)):\n",
    "    measurments_df= measurments_df.append({'method':'User average', 'mae_acc_prec_rec':maes_users[i], 'measurement_method':'MAE'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'User average', 'mae_acc_prec_rec':accs_users[i], 'measurement_method':'Accuracy'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'User average', 'mae_acc_prec_rec':precs_users[i], 'measurement_method':'Precision'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'User average', 'mae_acc_prec_rec':recs_users[i], 'measurement_method':'Recall'}, ignore_index = True)\n",
    "\n",
    "for i in range(len(maes_sim)):\n",
    "    measurments_df= measurments_df.append({'method':'Full-Similarity', 'mae_acc_prec_rec':maes_sim[i], 'measurement_method':'MAE'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Full-Similarity', 'mae_acc_prec_rec':accs_sim[i], 'measurement_method':'Accuracy'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Full-Similarity', 'mae_acc_prec_rec':precs_sim[i], 'measurement_method':'Precision'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Full-Similarity', 'mae_acc_prec_rec':recs_sim[i], 'measurement_method':'Recall'}, ignore_index = True)\n",
    "\n",
    "for i in range(len(maes_artists)):\n",
    "    measurments_df= measurments_df.append({'method':'Artist average', 'mae_acc_prec_rec':maes_artists[i], 'measurement_method':'MAE'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Artist average', 'mae_acc_prec_rec':accs_artists[i], 'measurement_method':'Accuracy'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Artist average', 'mae_acc_prec_rec':precs_artists[i], 'measurement_method':'Precision'}, ignore_index = True)\n",
    "    measurments_df= measurments_df.append({'method':'Artist average', 'mae_acc_prec_rec':recs_artists[i], 'measurement_method':'Recall'}, ignore_index = True)\n",
    "\n",
    "\n",
    "sns.barplot(data =  measurments_df[measurments_df['measurement_method']!= 'MAE'] , x= 'method', y='mae_acc_prec_rec', hue='measurement_method')\n",
    "plt.ylabel('Percent')\n",
    "\n",
    "plt.savefig('/data/all_measurements.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =  measurments_df[measurments_df['measurement_method']== 'MAE'] , x= 'method', y='mae_acc_prec_rec')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('data/mae.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group measurements (Only on bests method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG_measures_df =  pd.DataFrame()\n",
    "\n",
    "for i in range(len(groups_genres)):\n",
    "    NDCG_measures_df = NDCG_measures_df.append({'method':'Genre Similarity', 'ndcg':groups_genres[i], 'measurement_method':'NDCG'}, ignore_index = True)\n",
    "    NDCG_measures_df = NDCG_measures_df.append({'method':'User Similarity', 'ndcg':groups_user_avg[i], 'measurement_method':'NDCG'}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = NDCG_measures_df, x=\"method\", y=\"ndcg\")\n",
    "plt.ylim(0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe the watch the different techniques next to eachother\n",
    "\n",
    "sns.barplot(data = float_measurements_df, x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
